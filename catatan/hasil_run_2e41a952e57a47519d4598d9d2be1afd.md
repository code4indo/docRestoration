# Hasil Training Run: 2e41a952e57a47519d4598d9d2be1afd

**Tanggal**: 19 Oktober 2025  
**Experiment Name**: resume_adaptive_to_30_epochs_v2  
**Config File**: `configs/resume_adaptive_to_30_epochs.json`

## Executive Summary

Training ini merupakan kelanjutan dari experiment `fast_fail_adaptive_5epochs` yang di-resume hingga 30 epochs menggunakan arsitektur ENHANCED_V2 dengan adaptive loss balancing. Training masih berlangsung hingga epoch 26 dan menunjukkan performa yang sangat baik dengan CER mencapai 0.0577.

### Highlight Pencapaian
- ‚úÖ **Best Val CER**: 0.0577 (epoch 26) - **SANGAT BAIK**
- ‚úÖ **Best Val PSNR**: 29.90 dB (epoch 24) - **Mendekati target 30 dB**
- ‚úÖ **Best Val SSIM**: 0.9839 - **Melampaui target 0.95**
- ‚úÖ **Best Combined Score**: 26.74 (epoch 24)
- ‚ö†Ô∏è **CTC Loss Issue**: Raw CTC loss tinggi (~629), terkena clipping di 300

---

## 1. Hyperparameters

### Model Architecture
```json
{
  "generator_version": "enhanced_v2",
  "discriminator_version": "enhanced_v2",
  "vocab_size": 109
}
```

### Training Configuration
```json
{
  "epochs": 30,
  "batch_size": 2,
  "steps_per_epoch": 2133,
  "train_samples": 4266,
  "val_samples": 473,
  "seed": 42,
  "precision": "FP32",
  "gpu_id": "0"
}
```

### Learning Rates & Optimization
```json
{
  "lr_generator": 0.0002,
  "lr_discriminator": 0.0002,
  "gradient_clip_norm": 1.0,
  "discriminator_mode": "predicted"
}
```

### Loss Weights
```json
{
  "pixel_loss_weight": 200.0,
  "adv_loss_weight": 1.5,
  "rec_feat_loss_weight": 5.0,
  "ctc_loss_weight": 1.0,
  "perceptual_loss_weight": 0.2,
  "ctc_loss_clip_max": 300.0
}
```

### Adaptive Loss Balancing
```json
{
  "adaptive_loss_balancing": true,
  "target_ctc_ratio": 0.65,
  "target_visual_ratio": 0.35,
  "adaptation_rate": 0.15
}
```

### Early Stopping (Configured but Not Active)
```json
{
  "early_stopping": true,
  "patience": 15,
  "min_delta": 0.01,
  "restore_best_weights": true
}
```

**Note**: Meskipun early_stopping dikonfigurasi `true` di config, MLflow mencatat parameter `early_stopping: False` dan `patience: 0`, yang berarti early stopping tidak aktif dalam training ini.

---

## 2. Riwayat Metrik Training

### Progress Timeline (Epoch 17-26)

| Epoch | Val CER | Val PSNR | Val SSIM | Val WER | Combined Score | Patience |
|-------|---------|----------|----------|---------|----------------|----------|
| 17 | 0.0639 | 29.10 | 0.9824 | 0.1179 | 25.91 | 0 |
| 18 | 0.0719 | 28.55 | 0.9815 | 0.1310 | - | 1 |
| 19 | 0.0611 | 28.86 | 0.9807 | 0.1154 | - | 2 |
| 20 | 0.0659 | 28.51 | 0.9801 | 0.1213 | - | 3 |
| 21 | 0.0590 | 29.58 | 0.9837 | 0.1093 | 26.63 | 0 |
| 22 | 0.0647 | 29.21 | 0.9819 | 0.1163 | - | 1 |
| 23 | 0.0595 | 29.41 | 0.9838 | 0.1137 | - | 2 |
| 24 | 0.0631 | **29.90** | 0.9815 | 0.1104 | **26.74** | 0 |
| 25 | 0.0593 | 29.23 | 0.9816 | 0.1108 | - | 1 |
| 26 | **0.0577** | 29.39 | **0.9839** | **0.1086** | - | 2 |

### Best Metrics Evolution

**Combined Score Progression:**
- Epoch 4: 21.03
- Epoch 5: 21.68
- Epoch 6: 23.14
- Epoch 8: 23.77
- Epoch 9: 24.85
- Epoch 14: 25.17
- Epoch 15: 25.70
- Epoch 17: 25.91
- Epoch 21: 26.63
- **Epoch 24: 26.74** ‚Üê Best

**CER Evolution:**
- Epoch 4: 0.0909
- Epoch 5: 0.0835
- Epoch 6: 0.0790
- Epoch 8: 0.0727
- Epoch 9: 0.0688
- Epoch 14: 0.0667
- Epoch 15: 0.0635
- Epoch 24: 0.0631 (best recorded)
- **Epoch 26: 0.0577** ‚Üê Current Best (belum tercatat sebagai best)

**PSNR Evolution:**
- Epoch 4: 25.57 dB
- Epoch 5: 25.86 dB
- Epoch 6: 27.09 dB
- Epoch 8: 27.40 dB
- Epoch 9: 28.29 dB
- Epoch 14: 28.51 dB
- Epoch 15: 28.88 dB
- Epoch 17: 29.10 dB
- Epoch 21: 29.58 dB
- **Epoch 24: 29.90 dB** ‚Üê Best

---

## 3. Analisis Loss Components

### Generator Loss Trajectory (Epoch 17-26)
```
Epoch 17: 214.32
Epoch 18: 244.12
Epoch 19: 273.41
Epoch 20: 303.64
Epoch 21: 303.72
Epoch 22: 302.98
Epoch 23: 302.69
Epoch 24: 303.20
Epoch 25: 303.42
Epoch 26: 303.22
```

**Observasi**: Generator loss meningkat signifikan dari epoch 17 (214.32) ke epoch 20 (303.64) kemudian stabil di plateau ~303. Ini menunjukkan konvergensi ke equilibrium baru.

### Discriminator Loss (Epoch 17-26)
```
Stabil di range: 1.363 - 1.366
```

**Observasi**: Discriminator loss sangat stabil, menunjukkan keseimbangan yang baik dengan generator.

### CTC Loss Analysis

**Clipped CTC Loss (yang digunakan dalam backprop):**
```
Epoch 17-26: 297.27 - 298.22
Rata-rata: ~297.8
```

**Raw CTC Loss (sebelum clipping):**
```
Epoch 17: 627.01
Epoch 18: 627.73
Epoch 19: 628.06
Epoch 20: 627.69
Epoch 21: 628.99
Epoch 22: 628.63
Epoch 23: 628.95
Epoch 24: 628.82
Epoch 25: 629.64
Epoch 26: 629.29
```

**‚ö†Ô∏è CRITICAL INSIGHT**: Raw CTC loss konsisten tinggi (~627-629), **selalu terkena clipping** di threshold 300. Ini berarti:
1. Model kesulitan mempelajari alignment sequence untuk HTR
2. CTC loss clip melindungi training dari gradient explosion
3. Improvement CER terjadi meskipun CTC loss tinggi - kemungkinan karena kombinasi dengan recognition feature loss

### Visual Quality Losses (Improving Consistently)

**Pixel Loss (L1):**
```
Epoch 17: 0.007541 ‚Üí Epoch 26: 0.006736 (‚Üì 10.7%)
```

**Perceptual Loss:**
```
Epoch 17: 14.912 ‚Üí Epoch 26: 13.303 (‚Üì 10.8%)
```

**Recognition Feature Loss:**
```
Epoch 17: 0.019220 ‚Üí Epoch 26: 0.014121 (‚Üì 26.5%)
```

**Adversarial Loss:**
```
Stabil di range: 0.7904 - 0.7942
```

**‚úÖ INSIGHT POSITIF**: Semua visual quality losses menunjukkan tren penurunan yang konsisten, menandakan peningkatan kualitas visual restoration.

---

## 4. Gradient Analysis

### Generator Gradients

**Mean Gradient Norm:**
```
Epoch 17: 30.08
Epoch 18: 29.12
Epoch 19: 30.19
Epoch 20: 32.67
Epoch 21: 29.83
Epoch 22: 29.47
Epoch 23: 31.66
Epoch 24: 27.58
Epoch 25: 27.95
Epoch 26: 27.95
```

**Max Gradient Norm (‚ö†Ô∏è SPIKES!):**
```
Epoch 17: 406.98
Epoch 18: 266.91
Epoch 19: 1509.82
Epoch 20: 6413.82  ‚Üê EXTREME SPIKE!
Epoch 21: 1425.82
Epoch 22: 401.72
Epoch 23: 7494.11  ‚Üê EXTREME SPIKE!
Epoch 24: 356.24
Epoch 25: 926.32
Epoch 26: 449.75
```

**‚ö†Ô∏è WARNING**: Generator mengalami gradient spikes yang sangat tinggi (hingga 7494 di epoch 23). Meskipun gradient clipping (norm=1.0) melindungi dari update yang tidak stabil, spike ini mengindikasikan:
- Potential numerical instability di beberapa layer
- Kemungkinan issue pada CTC computation
- Perlu monitoring lebih lanjut untuk memastikan stability

### Discriminator Gradients (Stable)

**Mean Gradient Norm:**
```
Epoch 17-26: 12.52 - 13.64 (sangat stabil)
```

---

## 5. Performance Metrics Summary

### Current State (Epoch 26)
- **Validation CER**: 0.0577 ‚Üê **NEW BEST!**
- **Validation WER**: 0.1086
- **Validation PSNR**: 29.39 dB
- **Validation SSIM**: 0.9839
- **Epoch Time**: ~1603 seconds (~26.7 menit)

### Recorded Best Metrics
- **Best Combined Score**: 26.74 (Epoch 24)
- **Best Val CER**: 0.0631 (Epoch 24) - *akan diupdate ke 0.0577*
- **Best Val PSNR**: 29.90 dB (Epoch 24)
- **Best Val SSIM**: 0.9839 (Epoch 26)

### Training Efficiency
- **Time per Epoch**: ~1602-1603 seconds (konsisten)
- **Samples per Second**: 
  - Training: 4266 samples / 1603s ‚âà 2.66 samples/s
  - Validation: 473 samples (included in epoch time)

---

## 6. Perbandingan dengan Target Penelitian

| Metric | Target | Achieved | Status |
|--------|--------|----------|--------|
| PSNR | ~30 dB | 29.90 dB | ‚úÖ 99.7% dari target |
| SSIM | ~0.95 | 0.9839 | ‚úÖ **Melampaui 103.6%** |
| CER | - | 0.0577 | ‚úÖ **Excellent** (5.77% error rate) |
| WER | - | 0.1086 | ‚úÖ **Good** (10.86% error rate) |

---

## 7. Key Findings & Insights

### ‚úÖ Strengths

1. **Outstanding HTR Performance**
   - CER 0.0577 menunjukkan model sangat akurat dalam recognizing text
   - Tren improvement konsisten dari epoch 4 (0.0909) ‚Üí epoch 26 (0.0577)
   - WER juga membaik dari 0.1179 (epoch 17) ‚Üí 0.1086 (epoch 26)

2. **Excellent Visual Quality**
   - SSIM 0.9839 melampaui target 0.95
   - PSNR 29.90 dB sangat dekat dengan target 30 dB
   - Semua visual losses (pixel, perceptual, rec_feat) menurun konsisten

3. **Stable Training Dynamics**
   - Discriminator loss sangat stabil (~1.36)
   - Generator-Discriminator equilibrium tercapai
   - Epoch time konsisten (~1603s)

4. **Effective Loss Balancing**
   - Adaptive loss balancing sepertinya bekerja dengan baik
   - Visual dan recognition objectives seimbang
   - Combined score meningkat stabil

### ‚ö†Ô∏è Concerns & Issues

1. **High Raw CTC Loss**
   - Raw CTC loss ~629 sangat tinggi dan konsisten
   - Selalu terkena clipping di 300
   - Mengindikasikan model struggle dengan CTC alignment
   - **Rekomendasi**: Perlu investigasi lebih lanjut tentang:
     - Apakah sequence length/blanks ratio optimal?
     - Apakah charset/vocabulary sesuai dengan data?
     - Pertimbangkan adjusting `ctc_loss_clip_max` atau strategi alternatif

2. **Generator Gradient Spikes**
   - Spike hingga 7494 di epoch 23
   - Meskipun gradient clipping protect dari instability, ini bukan normal
   - **Rekomendasi**: 
     - Monitor apakah spike menyebabkan quality degradation
     - Consider investigating layer-wise gradient norms
     - Mungkin perlu mixed precision training (FP16) untuk numerical stability

3. **Early Stopping Not Active**
   - Config menunjukkan `early_stopping: true` dengan `patience: 15`
   - Tapi MLflow log menunjukkan `early_stopping: False`, `patience: 0`
   - **Inkonsistensi** antara config dan actual training
   - Training akan jalan hingga 30 epochs tanpa early stopping protection

4. **Patience Counter Behavior**
   - Patience counter mencapai 2 di epoch 26
   - Best epoch masih di 24 (PSNR-based)
   - Tapi epoch 26 memiliki CER lebih baik (0.0577 vs 0.0631)
   - **Question**: Apakah combined score metric optimal untuk best model selection?

### üîç Areas for Investigation

1. **CTC Loss Magnitude**
   - Why is raw CTC loss so high (~629)?
   - Is this normal for vocabulary size 109?
   - Would different CTC implementation help?

2. **Best Model Criterion**
   - Epoch 24: Best PSNR (29.90), CER (0.0631)
   - Epoch 26: Better CER (0.0577), Comparable PSNR (29.39)
   - Should we prioritize CER over combined score for HTR tasks?

3. **Continuation Strategy**
   - Training akan continue hingga epoch 30
   - Apakah 4 epoch lagi akan membawa improvement signifikan?
   - Atau sudah plateau?

---

## 8. Recommendations

### Immediate Actions

1. **Monitor Remaining Epochs (27-30)**
   - Track apakah CER terus menurun
   - Watch for overfitting signs
   - Check if gradient spikes persist

2. **Save Best CER Model**
   - Ensure epoch 26 (atau epoch dengan CER terbaik) di-save
   - Jangan hanya rely pada combined score untuk selection

### Short-term Improvements

1. **CTC Loss Investigation**
   ```python
   # Analyze CTC internals
   - Check sequence length distribution
   - Analyze blank token ratio
   - Verify label encoding correctness
   - Consider CTC loss normalization alternatives
   ```

2. **Gradient Stability**
   ```python
   # Add detailed gradient logging
   - Layer-wise gradient norms
   - Identify which layer causes spikes
   - Consider gradient accumulation
   - Test mixed precision (FP16/AMP)
   ```

3. **Config Consistency Check**
   ```bash
   # Verify why early_stopping not active
   - Check train_enhanced.py argument parsing
   - Ensure config JSON properly loaded
   - Add validation for config vs actual params
   ```

### Long-term Strategy

1. **Hyperparameter Tuning**
   - Experiment with different `ctc_loss_clip_max` values
   - Try different loss weight ratios
   - Test adaptive learning rate scheduling

2. **Architecture Experiments**
   - Try different CTC decoder configurations
   - Experiment with attention-based recognition (alternative to CTC)
   - Test batch size impact on CTC loss

3. **Dataset Analysis**
   - Verify ground truth quality
   - Check for label noise
   - Analyze failure cases (highest CER samples)

---

## 9. Comparison with Baseline (Souibgui et al.)

**Note**: Perlu data baseline untuk comparison yang akurat. Berdasarkan target metrics:

| Aspect | Baseline Target | This Run | Delta |
|--------|----------------|----------|-------|
| PSNR | ~30 dB | 29.90 dB | -0.10 dB (99.7%) |
| SSIM | ~0.95 | 0.9839 | +0.0339 (+3.6%) |
| Model | Baseline | Enhanced_V2 | ‚úÖ Improved architecture |
| CER | - | 0.0577 | ‚úÖ Strong performance |

---

## 10. Conclusion

Training run `2e41a952e57a47519d4598d9d2be1afd` menunjukkan **performa yang sangat baik** dengan:

- ‚úÖ CER 0.0577 (5.77% error rate) - excellent untuk HTR
- ‚úÖ PSNR 29.90 dB - mendekati target 30 dB  
- ‚úÖ SSIM 0.9839 - melampaui target 0.95
- ‚úÖ Stable training dengan consistent improvement

**Namun** masih ada **concern penting**:
- ‚ö†Ô∏è Raw CTC loss sangat tinggi (~629)
- ‚ö†Ô∏è Generator gradient spikes perlu investigation
- ‚ö†Ô∏è Early stopping configuration inconsistency

**Next Steps**:
1. Monitor epochs 27-30 untuk final results
2. Investigate CTC loss issue
3. Analyze gradient spike root cause
4. Prepare best model untuk evaluation dengan real data

**Potensi Novelty**:
- Arsitektur Enhanced_V2 dengan dual-modal discriminator
- Adaptive loss balancing mechanism
- High SSIM achievement (0.9839) sambil maintain strong HTR performance

Training ini menunjukkan **progress yang menjanjikan** menuju publikasi Q1, dengan beberapa area yang perlu di-refine untuk strengthening novelty claim.

---

## Appendix A: Full Hyperparameter List

```
adv_loss_weight: 1.5
batch_size: 2
contrastive_loss_weight: 0.0
ctc_loss_clip_max: 300.0
ctc_loss_weight: 1.0
discriminator_mode: predicted
early_stopping: False  # Inconsistent with config
epochs: 30
gradient_clip_norm: 1.0
lr_discriminator: 0.0002
lr_generator: 0.0002
min_delta: 0
patience: 0  # Inconsistent with config
pixel_loss_weight: 200.0
precision: FP32
rec_feat_loss_weight: 5.0
train_samples: 4266
val_samples: 473
vocab_size: 109
```

## Appendix B: Complete Metrics at Epoch 26

```
train/g_loss: 303.218
train/d_loss: 1.365
train/pixel_loss: 0.006736
train/adv_loss: 0.791770
train/rec_feat_loss: 0.014121
train/ctc_loss: 297.951
train/ctc_loss_raw: 629.288
train/perceptual_loss: 13.303
train/g_grad_norm_mean: 27.948
train/g_grad_norm_max: 449.749
train/d_grad_norm_mean: 13.269

val/cer: 0.057741
val/wer: 0.108585
val/psnr: 29.389
val/ssim: 0.983883

best_epoch: 24
best_val_cer: 0.063105
best_val_psnr: 29.898
best_combined_score: 26.743
patience_counter: 2
epoch_time_seconds: 1603.283
```

---

**Generated**: 19 Oktober 2025  
**Run ID**: 2e41a952e57a47519d4598d9d2be1afd  
**Status**: Training in progress (Epoch 26/30)
