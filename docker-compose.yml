services:
  # GAN-HTR Training Service (Manual Control - Container Idle)
  gan-htr-prod:
    image: jatnikonm/gan-htr:latest
    container_name: gan-htr-prod
    restart: unless-stopped
    # GPU support (comment out jika server tidak punya GPU)
    # runtime: nvidia  # Uncomment untuk GPU mode (Docker Compose v1)
    # deploy:          # GPU mode untuk Docker Compose v2
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           count: all
    #           capabilities: [gpu]
    volumes:
      # Include docRestoration directory (training code + scripts)
      - .:/workspace/docRestoration
      # Training outputs (persistent)
      - ./outputs:/workspace/outputs
      - ./logbook:/workspace/logbook
      # HuggingFace cache (persistent untuk avoid re-download)
      - gan-htr-huggingface:/root/.cache/huggingface
      - gan-htr-poetry:/root/.cache/poetry
      # Data volumes (akan di-download dari HuggingFace)
      - gan-htr-data:/workspace/dual_modal_gan/data
      - gan-htr-models:/workspace/models
      - gan-htr-charlist:/workspace/real_data_preparation
      # MLflow runs (persistent)
      - ./mlruns:/workspace/mlruns
    environment:
      - CUDA_VISIBLE_DEVICES=0
      - TF_FORCE_GPU_ALLOW_GROWTH=true
      - PYTHONUNBUFFERED=1
      - HF_HUB_ENABLE_HF_TRANSFER=0
      - HF_USERNAME=jatnikonm
      - HF_REPO_NAME=HTR_VOC
      - PYTHON_BIN=/usr/bin/python3
    ports:
      - "5001:5000/tcp"
      - "6007:6006/tcp"
      - "8889:8888/tcp"
    tty: true
    stdin_open: true
    working_dir: /workspace/docRestoration
    # Container idle - download data only, no auto-training
    command: >
      bash -c "
      echo 'ðŸŽ¯ GAN-HTR Container - Manual Mode (CPU-only)';
      echo '=====================================';
      echo '';
      echo 'âš ï¸  Running in CPU mode (no GPU detected)';
      echo 'âš ï¸  Training will be SLOW! Use GPU server for production.';
      echo '';
      echo 'ðŸ“¦ Checking and downloading data...';
      python3 /workspace/docRestoration/scripts/download_from_huggingface.py || echo 'âš ï¸ Download script not found';
      echo '';
      echo 'ðŸ“Š Starting MLflow UI server...';
      cd /workspace && mlflow ui --host 0.0.0.0 --port 5000 --backend-store-uri file:///workspace/mlruns > /tmp/mlflow_ui.log 2>&1 &
      sleep 3;
      echo 'âœ… MLflow UI: http://localhost:5001';
      echo '';
      echo 'âœ… Container ready - IDLE mode';
      echo '';
      echo 'ðŸš€ To start training manually, run:';
      echo '   docker exec -d gan-htr-prod bash /workspace/docRestoration/scripts/train32_production.sh';
      echo '';
      echo '   Or smoke test:';
      echo '   docker exec -d gan-htr-prod bash /workspace/docRestoration/scripts/train32_smoke_test.sh';
      echo '';
      echo 'ðŸ“Š Monitor: docker logs -f gan-htr-prod';
      echo 'ðŸ“Š MLflow UI: http://localhost:5001';
      echo '';
      echo 'ðŸ’¤ Container will stay idle until you start training...';
      tail -f /dev/null
      "

  # GAN-HTR Training Service with GPU (untuk server dengan GPU)
  gan-htr-prod-gpu:
    image: jatnikonm/gan-htr:latest
    container_name: gan-htr-prod-gpu
    restart: unless-stopped
    runtime: nvidia  # Docker Compose v1 GPU support
    # deploy:        # Docker Compose v2 GPU support (optional)
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           count: all
    #           capabilities: [gpu]
    volumes:
      # Include docRestoration directory (training code + scripts)
      - .:/workspace/docRestoration
      # Training outputs (persistent)
      - ./outputs:/workspace/outputs
      - ./logbook:/workspace/logbook
      # HuggingFace cache (persistent untuk avoid re-download)
      - gan-htr-huggingface:/root/.cache/huggingface
      - gan-htr-poetry:/root/.cache/poetry
      # Data volumes (akan di-download dari HuggingFace)
      - gan-htr-data:/workspace/dual_modal_gan/data
      - gan-htr-models:/workspace/models
      - gan-htr-charlist:/workspace/real_data_preparation
      # MLflow runs (persistent)
      - ./mlruns:/workspace/mlruns
    environment:
      - CUDA_VISIBLE_DEVICES=0
      - TF_FORCE_GPU_ALLOW_GROWTH=true
      - PYTHONUNBUFFERED=1
      - HF_HUB_ENABLE_HF_TRANSFER=0
      - HF_USERNAME=jatnikonm
      - HF_REPO_NAME=HTR_VOC
      - PYTHON_BIN=/usr/bin/python3
    ports:
      - "5001:5000/tcp"
      - "6007:6006/tcp"
      - "8889:8888/tcp"
    tty: true
    stdin_open: true
    working_dir: /workspace/docRestoration
    command: >
      bash -c "
      echo 'ðŸŽ¯ GAN-HTR Container - Manual Mode (GPU)';
      echo '=====================================';
      echo '';
      echo 'ðŸ” GPU Check...';
      python3 -c 'import tensorflow as tf; print(\"GPU:\", len(tf.config.list_physical_devices(\"GPU\")), \"device(s)\")' 2>&1 | tail -1;
      echo '';
      echo 'ðŸ“¦ Checking and downloading data...';
      python3 /workspace/docRestoration/scripts/download_from_huggingface.py || echo 'âš ï¸ Download script not found';
      echo '';
      echo 'ðŸ“Š Starting MLflow UI server...';
      cd /workspace && mlflow ui --host 0.0.0.0 --port 5000 --backend-store-uri file:///workspace/mlruns > /tmp/mlflow_ui.log 2>&1 &
      sleep 3;
      echo 'âœ… MLflow UI: http://localhost:5001';
      echo '';
      echo 'âœ… Container ready - IDLE mode';
      echo '';
      echo 'ðŸš€ To start training manually, run:';
      echo '   docker exec -d gan-htr-prod bash /workspace/docRestoration/scripts/train32_production.sh';
      echo '';
      echo '   Or smoke test:';
      echo '   docker exec -d gan-htr-prod bash /workspace/docRestoration/scripts/train32_smoke_test.sh';
      echo '';
      echo 'ðŸ“Š Monitor: docker logs -f gan-htr-prod';
      echo 'ðŸ“Š MLflow UI: http://localhost:5001';
      echo '';
      echo 'ðŸ’¤ Container will stay idle until you start training...';
      tail -f /dev/null
      "
    # profiles: [gpu]  # Profiles not supported in Docker Compose v1

  # Alternative: Auto-training mode (uncomment if needed)
  # gan-htr-auto:
  #   image: jatnikonm/gan-htr:latest
  #   container_name: gan-htr-auto
  #   restart: unless-stopped
  #   volumes:
  #     - .:/workspace/docRestoration
  #     - ./outputs:/workspace/outputs
  #     - ./logbook:/workspace/logbook
  #     - gan_data:/workspace/dual_modal_gan/data
  #     - htr_models:/workspace/models
  #     - charlist_data:/workspace/real_data_preparation
  #     - huggingface_cache:/root/.cache/huggingface
  #     - poetry_cache:/root/.cache/poetry
  #     - ./mlruns:/workspace/mlruns
  #   environment:
  #     - CUDA_VISIBLE_DEVICES=0
  #     - TF_FORCE_GPU_ALLOW_GROWTH=true
  #     - PYTHONUNBUFFERED=1
  #     - HF_USERNAME=jatnikonm
  #     - HF_REPO_NAME=HTR_VOC
  #     - MODE=production
  #     - TRAINING_SCRIPT=scripts/train32_production.sh
  #   entrypoint: ["/workspace/docRestoration/entrypoint.sh"]
  #   working_dir: /workspace/docRestoration

  # Test container (validation only - no training)
  gan-htr-test:
    image: jatnikonm/gan-htr:latest
    container_name: gan-htr-test
    volumes:
      - .:/workspace/docRestoration
      - ./logbook:/workspace/logbook
      - gan-htr-huggingface:/root/.cache/huggingface
      - gan-htr-poetry:/root/.cache/poetry
    environment:
      - CUDA_VISIBLE_DEVICES=0
      - TF_FORCE_GPU_ALLOW_GROWTH=true
      - PYTHONUNBUFFERED=1
      - TEST_MODE=true
      - MODE=test
    command: >
      bash -c "echo 'ðŸ§ª Test container started' && python3 -c 'import tensorflow as tf; print(\"âœ… TensorFlow found:\", tf.__version__); print(\"âœ… GPU:\", len(tf.config.list_physical_devices(\"GPU\"))); print(\"âœ… GPU acceleration available\" if tf.config.list_physical_devices(\"GPU\") else \"âš ï¸ GPU not detected or not working\")' && echo 'âœ… Test passed - Container ready!'"

  # Development override (optional)
  gan-htr-dev:
    image: jatnikonm/gan-htr:latest
    container_name: gan-htr-dev
    volumes:
      - .:/workspace/docRestoration
      - ./outputs:/workspace/outputs
      - ./logbook:/workspace/logbook
      - gan-htr-data:/workspace/dual_modal_gan/data
      - gan-htr-models:/workspace/models
      - gan-htr-charlist:/workspace/real_data_preparation
      - gan-htr-huggingface:/root/.cache/huggingface
      - gan-htr-poetry:/root/.cache/poetry
      - ./mlruns:/workspace/mlruns
    environment:
      - DEVELOPMENT_MODE=true
      - DEBUG=true
      - HF_USERNAME=jatnikonm
      - HF_REPO_NAME=HTR_VOC
      - MODE=development
      - CUDA_VISIBLE_DEVICES=0
      - TF_FORCE_GPU_ALLOW_GROWTH=true
    working_dir: /workspace/docRestoration
    command: >
      bash -c "echo 'ðŸ”§ Development mode - Interactive shell' && tail -f /dev/null"
    tty: true
    stdin_open: true

# Named volumes (Docker will create automatically)
volumes:
  gan-htr-huggingface:
  gan-htr-poetry:
  gan-htr-data:
  gan-htr-models:
  gan-htr-charlist:
